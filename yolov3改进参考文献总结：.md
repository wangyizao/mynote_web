### yolov3改进参考文献总结：



邵文杰，提出基于YOLOv3模型，通过vggnet和DenseNet替换原来的backbone网络，实验证明vggnet检测速度快，但精度不高；DenseNet提高了检测精度，但是需要大量的计算和内存去换取少许精度的提升。最后通过在重点区域和通道添加注意力机制去提高检测精度，是本文的重点。在三个提取特征中加入CBAM。

![image-20220321192910863](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321192910863.png)

在2016年，吴建等使用传统计算机视觉技术将无用垃圾与科研室的背景分离，提出了科研室场景下垃圾分析与识别的方法。

2019年，张鹏程等提出了一种城市街道清洁度评估方法，该方法在对图像存储的同时还可以预处理图像。

传统：随着DPM(Deformable Part Model)算法

多层感知机





传统机器学习检测：

王敏等[11]提出了一种水面漂浮物检测分割算法，该算法利用水面和漂 浮物之间的饱和度之差这一特性来提取水面区域，然后利用区域一致性的 GOA 进行边缘检测和目标定位。Imtiaz Ali 等[12]通过结合图像强度与时间概率图来设 置阈值，并根据阈值将水面与木头碎屑进行分割。左建军等[13]通过布设监控设备 来获取水面影像，采用背景减除方法分割影像中包含漂浮物的区域，然后用该区硕士学位论文 域对 BP 算法进行特征训练，最后利用分类器分类识别漂浮物。杨鹏[14]通过布设 监控设备来检测水面，采用 Mean Shift 算法对图像进行分割算法，并根据分割结 果预估污染物种类和污染程度，然后将颜色矩作为特征进行提取，最后利用支持 向量机分类器对漂浮物进行训练和识别。胡蓉[5]通过高清摄像头采集水面图像， 利用 K 均值聚类法、边缘分割法、模糊阈值法等分割方法对图像中的漂浮垃圾 进行分割，并将这些分割图进行合并得到分割二值图，然后根据漂浮垃圾的面积 特征对分割二值图进行特征提取，最后利用支持向量机、BP 神经网络、决策树 等分类器对漂浮垃圾进行分类识别。汤伟等[15]采用改进的最大类间方差（OTSU） 法分割水面漂浮垃圾，然后计算目标的中心点坐标和最小外界矩对目标进行标记 来实现水面机器人自动清扫垃圾的功能。徐守坤等[16]通过将一维 Otsu 法和均匀 性测度函数相结合，提出了一种基于均匀性测度函数的阈值分割法，更好地分割 出水面漂浮物区域。

深度学习：

魏莉莉[18]通过在无人艇上架设双目相 机来实现实时测距功能并采集水面影像，然后基于 TensorFlow 框架利用风格迁 移算法构建目标识别模块,通过 VGG 网络进行特征提取，最终分类识别水面漂浮 物。唐小敏等[19]通过无人机采集河流视频影像，并利用视频截取的图像来训练基 于 ResNet-101 的 SSD 和 Faster R-CNN 模型，经过对比分析基于 ResNet-101 的 SSD 具有更高的检测精度。 

2021年，李德鑫，首先针对数据集，YOLOv5s 算法中数据增强分为图像增强和 Mosaic 增强。图像增强主要包括图像的仿射、透视等，使算法能够感受同一目标的不同形态，来减轻算法的过拟 合现象；Mosaic 增强通过随机缩放、裁剪、排列等方式，最多将四张影像拼接 成一张影像，以此来提高物体的检测精度。针对 YOLOv5s 目标检测算法在检测小目标与类别不均衡目标方面存 在的不足，利用 K-means 聚类方法重新标定了算法的先验锚框，并对数据增强、 SPP 以及损失函数等模块进行了改进。在 SPP 模块中增加了一个 3×3 的 卷积核来提升模型的感受野，从而提高小目标的检测精度--针对河道漂浮垃圾在无人机影像中占比较小，在 SPP 模块中，将最大值池化的滤波器由原来的 5*5，9*9，13*13 增加为 3*3，5*5，9*9，13*13，来进一 步提升模型的感受野，从而提高小目标的检测精度；在 YOLOv5 损失函数中，置信度和类别损失采用的是二进制交叉熵损失，它给予每一类目标相同的权重值，因此不利于类别不均衡的河流漂浮物的检测。 本文采用 Focal 损失函数来计算置信度和类别的损失。通过在自制的数据集中对改进前与改进后的算法进行性能测试，发现改进后的算法降低了小目标的漏检率，类别均衡准确率提升了3.47%，各类别检测精度也均有提升。

![image-20220321193008840](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321193008840.png)

Focus 模块相当于将输入的图像先复制四份，然后每一份图像都隔像 素取值，最后将四份图像进行通道融合（Concat），这样就得到了没有丢失信息 的二倍下采样图。

![image-20220321180529477](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321180529477.png)











SPP（空间金字塔池化）模块是将输入图像分别进行滤波器为 5*5、9*9、13*13 的最大值池化，然后将原图像与池化后的三幅图像进行通道融合。

![image-20220321180730591](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321180730591.png)





其中 FPN 层负责将顶层丰富的语义特征传往 底层，PAN 层负责将底层的精确定位信息传往顶层，两者互相补充既提高了模 型预测框位置的精度又提高了预测框类别的准确度。





![image-20220321181150983](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321181150983.png)





小目标检测存在的问题：

对小目标检测的研究还不成熟，小目标分辨率低、像素占比少． 小目标物体其自身占有固定的低分辨率，在目标检测过程中提取到的有效信息十分有限; 卷积神经网络中深层感受野大，经过多次下采样后特征图不断减小，更难提取特征，导致小目标检测存在严重的物体漏检、误检等情况。





2020年，罗建华，在原有基础上新增一个检测尺度，为104 × 104 的特征层，用于将浅层信息提取出来． 将 104 × 104 的特征层与其他 3 个特征层进行融合，形成新的特征提取网络． 使得 浅层的特征具有较强的位置信息，深层的特征具有较强的语义信息，在降低小目标的漏检率的同时还增强定位的精度．再使用GIOU替代IOU。本文使用优化后的 K-means ++ 聚类算法，对混合数据集 进行聚类分析． 保持 K 值为 9 不变，经聚类算法迭代后选取的对应 Anchor Box 的宽高分别为( 14，\37) 、( 8，\77) 、( 23， \53) 、( 18，\136) 、( 37，\76) 、( 60，\108) 、( 38，\261) 、( 93，\173) 、( 147，291)

![image-20220321193127489](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321193127489.png)







2021年，杨立功等人采用基于 PANet［11］（Path Aggregation Network） 网络中的多尺度特征增强方式，对 YOLOV3 模型进行改进，使模型更加适用于复杂地面战场环境下小目标的检测识别。

![image-20220321184832286](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321184832286.png)





2021年，谭芳喜。通过深度可分离卷积模块减少模型计算量，提高模型的实时性; 采用 K－Means++聚类算法代替原来的 K－Means 算法生成本数据集所需的先验锚点框，解决 K－Means 算法受初始点选取的影响较大，聚类效果不稳定的问题; 在 YOLOv3 的多尺度预测网络中引入SENet( squeeze－and－excitation networks) ，加强网络对特征的学习能力; 改进位置损失函数，解决使用 IoU( intersection over union) 度量时存在无法反映预测框与真实框重合度大小、无法优化 IoU 为零等问题; 利用 DIoU－NMS( 基于 Distance－IoU 的非极大值抑制) 去除冗余框，减少错误抑制，提高检测精度。

![image-20220321185611865](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321185611865.png)





2020年，孙佳等人首先，提出的k-means-threshold(k-thresh)方法弥补了k-means算法对聚类中心初始位置十分敏感的问题，在包括三个类别的数据集中进行聚类分析选择合适的锚框；然后，将４倍下采样和８倍下采样特征图拼接融入第三个检测层，以提高对目标的检测精度，将 ＹＯＬＯｖ３算法的平均准确率均值提高了２％；最 后，通过摄像头捕捉图像和前期得到的优秀检测数据来预测新图像的目标以及加入了重新检测阈值，以提高视频检测流畅度。

k-thresh:首先通过k-means算法进行“粗”聚类，此时可能得到一个好的聚类结果也可能是不好的聚类结果，然后通过阈值选择好的 聚 类 结 果 为 新 的 聚 类 中 心，再 次 通 过k-means算法进行“细”聚类得到最终的聚类结果。

![image-20220321190759360](C:\Users\15118\AppData\Roaming\Typora\typora-user-images\image-20220321190759360.png)





总结：大部分对于yolov3的改进都是基于：

1. 锚选框的重聚类，一般采用k-means++，或者k-thresh。
2. 进行更高层的特征融合，把第二层提取的特征也下采样与第三层的特征进行contact。有的人为了达到更好的小目标检测效果，把第二层添加到预测中。
3. 在关键通道中添加注意力机制，有的添加在特征融合之后，有的添加在特征融合之前。
4. 在预测前通过把融合过得上层特征再经过下采样与深层的特征进行contact，然后在进行预测。
5. yolov3位置损失函数，使用 IoU( intersection over union) 度量时，存在无法反映预测框与真实框重合度大小、无法优化 IoU 为零等问题。故采用diou或者giou等方法对iou进行替换。
6. 为了提高实时性，采用剪枝的方法减少参数量，也有采用可分离卷积替换全卷积，减少参数量。
7. 